---
title: "Airbnb Review Scores Rating Exploration and Prediction: Empirical Evidence from Hong Kong"
date: "15/01/2021"
authour: Minhui Ma
output: 
  html_document:
    toc: true
    toc_float: true
    toc_collapsed: true
    toc_depth: 5
number_sections: true
theme: lumen
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, warning = FALSE, error = FALSE, tidy = TRUE)
```

### 1. Abstract & Import Data
Inspired by the business success of Airbnb and the developed tourism industry in Hong Kong, in this project, we will explore the determinants of the Airbnb customer experience and aim to improve the performance of Airbnb hosts in Hong Kong. On the Airbnb website, listings are evaluated through six dimensions – accuracy, communication, cleanliness, check-in, location, and value. The empirical project will firstly analyze the order of importance of these six dimensions. Then using the dataset sourced from Inside Airbnb, we will investigate which features are crucial for customer satisfaction. Lastly, we will build customer experience models to predict the quality of listings.
  
#### 1.1. Import packages
```{r,results = 'hide',message=FALSE}
# import packages
library(tidyverse)
# library(geojsonio)
library(ggplot2)
library(plotly)
library(BBmisc)
library(corrplot)
library(e1071)
library(skimr)
library(stargazer)
library(tm)
library(tidytext)
library(DescTools)
# library(ISLR)
library(glmnet)
# library(factoextra)
library(randomForest)
library(MASS)
```
  
#### 1.2. Set seed
```{r,results = 'hide',message=FALSE}
# set seed
set.seed(123987)
```
  
#### 1.3. Import data
```{r,results = 'hide',message=FALSE}
listings <- read.csv("listings.csv", header = TRUE, sep = ",")
```
  
#### 1.4. Data skimming
```{r}
skim(listings)
```

### 2. Data cleaning
  
* Replace all empty values with NA 
```{r}
listings[listings==''] <- NA
listings[listings=='N/A'] <- NA
```
  
* Filter out rows with ```review_scores_rating``` in NA
```{r}
listings2 <- listings %>% filter(review_scores_rating != '')
```
  
* Drop all empty columns
```{r}
listings2 <- listings2[!sapply(listings,function(x)all(is.na(x)))]
```
  
* Drop columns with same value
```{r}
listings2 <- listings2 %>% dplyr::select(where(~length(unique(.)) > 1))
```
  
* For missing review scores of the 6 dimensions, let them equal to ```review_scores_rating```*0.1
```{r}
review_scores <- c('review_scores_accuracy','review_scores_checkin','review_scores_communication',
                   'review_scores_cleanliness','review_scores_value','review_scores_location')
for (i in review_scores){
  text <- paste("listings2$",i," <- ifelse(is.na(listings2$",i,"),listings2$review_scores_rating*0.1,listings2$",i,")",sep='')
  eval(parse(text= text))
}
```
  
* Convert currency values to numeric values
```{r}
listings2$price <- as.numeric(gsub('[$,]', '', listings2$price))
listings2$weekly_price <- as.numeric(gsub('[$,]', '', listings2$weekly_price))
listings2$monthly_price <- as.numeric(gsub('[$,]', '', listings2$monthly_price))
listings2$security_deposit <- as.numeric(gsub('[$,]', '', listings2$security_deposit))
listings2$cleaning_fee <- as.numeric(gsub('[$,]', '', listings2$cleaning_fee))
listings2$extra_people <- as.numeric(gsub('[$,]', '', listings2$extra_people))
```
  
* Replace date with its year
```{r}
var_date <- c('host_since','first_review','last_review')
for (i in var_date){
  text <- paste("listings2$",i," <- floor(as.integer(format(as.Date(listings2$",i,"),'%Y')))",sep='')
  eval(parse(text= text))
}
```
  
* Convert percentage values to numeric values, and replace missing values with 0
```{r}
listings2$host_response_rate <- as.numeric(sub("%","",listings2$host_response_rate))/100
listings2$host_response_rate[is.na(listings2$host_response_rate)] <- 0
listings2$host_acceptance_rate <- as.numeric(sub("%","",listings2$host_acceptance_rate))/100
listings2$host_acceptance_rate[is.na(listings2$host_acceptance_rate)] <- 0
```
  
* Drop variables
+ ```listing_url```, ```picture_url```, ```host_url```, ```host_thumbnail_url```, ```host_picture_url```
+ ```host_name```, ```name```
+ ```market```, ```state```, ```smart_location```, ```country_code```, ```country```
+ ```host_listings_count```, ```host_total_listings_count```
+ ```host_location```, ```host_neighbourhood```, ```street```, ```city```
+ ```neighbouthood```
+ ```zipcode```, ```square_feet```
+ ```availability_30```, ```availability_60```, ```availability_90```, ```availability_365```
+ ```last_scraped```, ```calendar_last_scraped```
+ ```host_id```
+ ```longitude```,```latitude```
```{r}
listings2 <- listings2 %>% 
  dplyr::select(-listing_url, -picture_url, -host_url, -host_thumbnail_url, -host_picture_url,
         -host_name, -name,
         -market, -state, -smart_location, -country_code, -country,
         -host_location, -host_neighbourhood, -street, -city,
         -host_listings_count, -host_total_listings_count, 
         -neighbourhood, 
         -zipcode, -square_feet,
         -availability_30, -availability_60, -availability_90, -availability_365,
         -last_scraped, -calendar_last_scraped,
         -host_id,
         -longitude, -latitude)
```
  
* Replace t with 1 and f with 0: ```host_has_profile_pic```, ```host_identity_verified```, ```host_is_superhost```, ```is_location_exact```, ```instant_bookable```, ```require_guest_profile_picture```, ```require_guest_phone_verification```
```{r}
listings2 <- listings2 %>% 
  mutate(host_has_profile_pic = ifelse(host_has_profile_pic == "t", 1, 0),
         host_identity_verified = ifelse(host_identity_verified == "t", 1, 0),
         host_is_superhost = ifelse(host_is_superhost == "t", 1, 0),
         is_location_exact = ifelse(is_location_exact == "t", 1, 0),
         instant_bookable = ifelse(instant_bookable == "t", 1, 0),
         require_guest_profile_picture = ifelse(require_guest_profile_picture == "t", 1, 0),
         require_guest_phone_verification = ifelse(require_guest_phone_verification == "t", 1, 0),)
var <- c('host_has_profile_pic','host_identity_verified','host_is_superhost','is_location_exact',
         'instant_bookable','require_guest_profile_picture','require_guest_phone_verification')
for (i in var){
  text <- paste(" listings2$",i,"[is.na(listings2$",i,")] <- 0",sep='')
  eval(parse(text= text))
}
```
 
* Replace missing values with mean values: ```host_since```, ```security_deposit```, ```cleaning_fee```
```{r}
listings2$host_since[is.na(listings2$host_since)] <- floor(mean(listings2$host_since[!is.na(listings2$host_since)]))
listings2$security_deposit[is.na(listings2$security_deposit)] <- floor(mean(listings2$security_deposit[!is.na(listings2$security_deposit)]))
listings2$cleaning_fee[is.na(listings2$cleaning_fee)] <- floor(mean(listings2$cleaning_fee[!is.na(listings2$cleaning_fee)]))
```
  
* Replace missing values with other values: ```monthly_price```, ```weekly_price```, ```host_response_time```
```{r}
listings2$weekly_price[is.na(listings2$weekly_price)] <- 7*listings2$price[is.na(listings2$weekly_price)]
listings2$monthly_price[is.na(listings2$monthly_price)] <- 30*listings2$price[is.na(listings2$monthly_price)]
listings2$host_response_time[is.na(listings2$host_response_time)] <- 'no response'
```
  
* Drop variables: ```summary```,  ```space```, ```description```, ```neighborhood_overview```, ```notes```, ```transit```, ```access```, ```interaction```, ```house_rules```, ```license```, ```host_about```, ```cancellation_policy```, ```host_about```, ```cancellation_policy```
* Drop variable ```is_location_exact```: unimportant as it could be inacurate up to 150 meters http://insideairbnb.com/about.html#disclaimers
* Drop variable ```calendar_updated```: we are not interested in future data that is a subject to daily updates
* Drop variable ```first_review``` and ```last_review```: we are not interested about when the reviews are given
* Add variable ```last_first_review```: we are interested about how many years the listing has been on Airbnb. Simply calculate it by ```first_review```-```last_review```
* Convert ```host_since``` into the years of experience of being a host
```{r}
listings2 <- listings2 %>% 
  dplyr::select(-summary, -space, -description, -neighborhood_overview, -notes, -transit, -access, -interaction, -house_rules, -license, -host_about, -cancellation_policy, -is_location_exact, -calendar_updated) %>% 
  mutate(last_first_review = first_review-last_review,
         host_experience_year = floor(2020-host_since)) %>% 
  dplyr::select(-first_review,-last_review,-host_since)
```
  
* Replace missing values with 0: ```bathrooms```,  ```beds``` 
```{r}
var0 <- c('bathrooms','beds','bedrooms')
for (i in var0){
  text <- paste("listings2$",i,"[is.na(listings2$",i,")] <- 0",sep='')
  eval(parse(text= text))
}
```
  
* Remove observations with 0 review
```{r}
listings2 <- listings2 %>% filter(number_of_reviews>0)
```

### 3. Exploratory Data Analysis
#### 3.1. Bed Type
```{r}
ggplot(listings2, aes(x = bed_type)) + 
  geom_bar(fill="black", colour="black", alpha = 0.25)
```
```{r}
listings2 %>% 
  count(bed_type) %>% 
  arrange(desc(n))
```
  
Only 44 listings have other types of beds instead of real beds. In this empirical project, we only consider real bed.
```{r}
listings2 <- listings2 %>% filter(bed_type == "Real Bed") %>% dplyr::select(-bed_type)
```

#### 3.2. Property Type
```{r}
listings2 %>%
    count(property_type) %>%
    mutate(property_type = fct_reorder(property_type, n, .desc = TRUE)) %>%
    ggplot(aes(x = property_type, y = n)) + 
  geom_bar(stat = 'identity', fill="black", colour="black", alpha = 0.25) + 
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5))
```
```{r}
property_cnt <- listings2 %>% 
  count(property_type) %>% 
  arrange(desc(n))
property_cnt
```
  
Airbnb has 36 types of property types in Hong Kong. However, only 11 property types have more than 50 observations. For property types that have less than 50 observations, we bucket them into an “other” category.
```{r}
listings2 <- listings2 %>% 
  merge(property_cnt, by = "property_type") %>% 
  mutate(property_type = case_when(
    n > 50 ~ property_type,
    TRUE ~ "other_property_types"
  )) %>% 
  dplyr::select(-n)
```

#### 3.3. Year
```{r}
paste("The earliest year of host_since is ",min(listings$host_since),", and the lastest year of host_since is ",max(listings$host_since),sep='')
paste("The earliest year of first_review is ",min(listings$first_review),", and the lastest year of first_review is ",max(listings$first_review),sep='')
paste("The earliest year of last_review is ",min(listings$last_review),", and the lastest year of last_review is ",max(listings$last_review),sep='')
```

#### 3.4. Scores correlation matrix
The empirical project is interested in the order of importance of these six dimensions. To see their correlations, a correlation matrix is created.
```{r}
listings_scores <- listings2 %>% 
  dplyr::select(review_scores_rating, 
         review_scores_accuracy, 
         review_scores_checkin, 
         review_scores_cleanliness, 
         review_scores_communication,
         review_scores_location, 
         review_scores_value) %>% 
  rename(scores = review_scores_rating, 
         accuracy = review_scores_accuracy, 
         checkin = review_scores_checkin, 
         cleanliness = review_scores_cleanliness, 
         communication = review_scores_communication,
         location = review_scores_location, 
         value = review_scores_value)
corrplot(cor(listings_scores), type = "lower", method = "number")
```
  
Accuracy, value, and cleanliness are the three most important dimensions, with correlations separately in 0.81, 0.80, and 0.79. However, location has a comparatively weak correlation with review scores rating, which is 0.61.

#### 3.5. CX scores
```review_scores_rating``` is an overall score on the AirBnb listing from 0 to 100. ```reviews_per_month``` is the number of reviews received by a listing per month.
  
##### 3.5.1. review_scores_rating
```{r}
ggplot(listings2, aes(x = review_scores_rating)) + 
  geom_histogram(fill="black", colour="black", alpha = 0.25, binwidth=1)
```
  
* maximum and minimum
```{r}
min(listings2$review_scores_rating)
max(listings2$review_scores_rating)
```
  
* skewness
```{r}
skewness(listings2$review_scores_rating)
```
  
* kurtosis
```{r}
kurtosis(listings2$review_scores_rating)
```
  
##### 3.5.2. reviews_per_month
```{r}
ggplot(listings2, aes(x = reviews_per_month)) + 
  geom_histogram(fill="black", colour="black", alpha = 0.25, binwidth=0.1)
```
  
* maximum and minimum
```{r}
min(listings2$reviews_per_month)
max(listings2$reviews_per_month)
```
  
* skewness
```{r}
skewness(listings2$reviews_per_month)
```
  
* kurtosis
```{r}
kurtosis(listings2$reviews_per_month)
```
  
##### 3.5.3. cx_scores
  
We consider a new variable CX scores calculated by simply multiplying together the normalized review scores rating with the number of reviews per month. 
  
Replace ```review_scores_rating``` with ```cx_scores``` and drop ```review_scores_rating```, ```review_scores_accuracy```, ```review_scores_checkin```, ```review_scores_cleanliness```, ```review_scores_communication```,```review_scores_location```, ```review_scores_value```, ```reviews_per_month```, ```number_of_reviews```, ```number_of_reviews_ltmh```, 
```{r}
listings3 <- listings2 %>% 
  mutate(cx_scores = review_scores_rating/100*reviews_per_month) %>%
  dplyr::select(-review_scores_rating, 
         -review_scores_accuracy, 
         -review_scores_checkin, 
         -review_scores_cleanliness, 
         -review_scores_communication,
         -review_scores_location, 
         -review_scores_value,
         -reviews_per_month,
         -number_of_reviews,
         -number_of_reviews_ltm)
```
```{r}
ggplot(listings3, aes(x = cx_scores)) + 
  geom_histogram(fill="black", colour="black", alpha = 0.25, binwidth=0.1)
```
  
* maximum, minimum and quantile
```{r}
min(listings3$cx_scores)
max(listings3$cx_scores)
IQR(listings3$cx_scores)
quantile(listings3$cx_scores)
```
  
* remove outliers
```{r}
# Identify outliers
outliers <- boxplot(listings3$cx_scores, plot = FALSE)$out
# Remove outliers
listings3 <- listings3[!(listings3$cx_scores %in% outliers), ]
# Quantile
quantile(listings3$cx_scores)
```

#### 3.6. Data skimming
```{r}
skim(listings3)
```

#### 3.7. Character variables
  
* property_type
```{r}
ggplot(data = listings3, aes(x = as.character(property_type), y = cx_scores, color = as.character(property_type))) +
  geom_boxplot(outlier.shape = NA, varwidth = TRUE) +
  theme(axis.text.x = element_text(angle = 90, hjust = 1),legend.position = "none")+
  coord_cartesian(ylim = c(0, 3)) +
  xlab("property_type")
```
  
* room_type
```{r}
ggplot(data = listings3, aes(x = as.character(room_type), y = cx_scores, color = as.character(room_type))) +
  geom_boxplot(outlier.shape = NA, varwidth = TRUE) +
  theme(axis.text.x = element_text(angle = 90, hjust = 1),legend.position = "none")+
  coord_cartesian(ylim = c(0, 3)) +
  xlab("room_type")
```
  
* neighbourhood_cleansed
```{r}
ggplot(data = listings3, aes(x = as.character(neighbourhood_cleansed), y = cx_scores, color = as.character(neighbourhood_cleansed))) +
  geom_boxplot(outlier.shape = NA, varwidth = TRUE) +
  theme(axis.text.x = element_text(angle = 90, hjust = 1),legend.position = "none")+
  coord_cartesian(ylim = c(0, 3)) +
  xlab("neighbourhood_cleansed")
```
  
* host_response_time
```{r}
ggplot(data = listings3, aes(x = as.character(host_response_time), y = cx_scores, color = as.character(host_response_time))) +
  geom_boxplot(outlier.shape = NA, varwidth = TRUE) +
  theme(axis.text.x = element_text(angle = 90, hjust = 1),legend.position = "none")+
  coord_cartesian(ylim = c(0, 3)) +
  xlab("host_response_time")
```

#### 3.8. Numeric Variables
  
Transform character variables into numeric variables
```{r}
listings4 <- listings3 %>% mutate(val1 = 1, val2 = 1, val3 = 1, val4 = 1, val5 = 1)
listings4 <- listings4 %>% 
  spread(host_response_time, val1, fill = 0) %>% 
  spread(neighbourhood_cleansed, val2, fill = 0) %>% 
  spread(property_type, val3, fill = 0) %>% 
  spread(room_type, val4, fill = 0)

listings4 <- listings4 %>% dplyr::select(-id)

names(listings4) <- gsub(" ", "_", names(listings4))
names(listings4) <- gsub("&", "", names(listings4))
names(listings4) <- gsub("/", "_", names(listings4))
names(listings4) <- gsub("__", "_", names(listings4))
```
  
* host_response_rate
```{r}
ggplot(listings4 %>% count(host_response_rate), aes(x = host_response_rate)) + 
  geom_histogram(fill="black", colour="black", alpha = 0.25, binwidth=0.1)
```
  
* host_acceptance_rate
```{r}
ggplot(listings4, aes(x = host_acceptance_rate)) + 
  geom_histogram(fill="black", colour="black", alpha = 0.25, binwidth=0.1)
```
  
* accommodates
```{r}
ggplot(listings4, aes(x = accommodates)) + 
  geom_histogram(fill="black", colour="black", alpha = 0.25, binwidth=1)
```
  
* bathrooms
```{r}
ggplot(listings4, aes(x = bathrooms)) + 
  geom_histogram(fill="black", colour="black", alpha = 0.25, binwidth=1)
```
  
* bedrooms
```{r}
ggplot(listings4, aes(x = bedrooms)) + 
  geom_histogram(fill="black", colour="black", alpha = 0.25, binwidth=1)
```
  
* beds
```{r}
ggplot(listings4, aes(x = beds)) + 
  geom_histogram(fill="black", colour="black", alpha = 0.25, binwidth=1)
```
  
* price
```{r}
ggplot(listings4, aes(x = price)) + 
  geom_histogram(fill="black", colour="black", alpha = 0.25, binwidth=1000)
```
  
* weekly_price
```{r}
ggplot(listings4, aes(x = weekly_price)) + 
  geom_histogram(fill="black", colour="black", alpha = 0.25, binwidth=10000)
```
  
* monthly_price
```{r}
ggplot(listings4, aes(x = monthly_price)) + 
  geom_histogram(fill="black", colour="black", alpha = 0.25, binwidth=100000)
```
  
* calculated_host_listings_count
```{r}
ggplot(listings4, aes(x = calculated_host_listings_count)) + 
  geom_histogram(fill="black", colour="black", alpha = 0.25, binwidth=10)
```
  
* calculated_host_listings_count_entire_homes
```{r}
ggplot(listings4, aes(x = calculated_host_listings_count_entire_homes)) + 
  geom_histogram(fill="black", colour="black", alpha = 0.25, binwidth=5)
```
  
* calculated_host_listings_count_private_rooms
```{r}
ggplot(listings4, aes(x = calculated_host_listings_count_private_rooms)) + 
  geom_histogram(fill="black", colour="black", alpha = 0.25, binwidth=10)
```
  
* calculated_host_listings_count_shared_rooms
```{r}
ggplot(listings4, aes(x = calculated_host_listings_count_shared_rooms)) + 
  geom_histogram(fill="black", colour="black", alpha = 0.25, binwidth=1)
```

#### 3.9. Amenities & Host_verifications
  
To transform these two variables into numeric ones, there are two approaches. Firstly, we can simply count the number of amenities and host verifications. Secondly, we can apply natural language processing to see the most popular amenities and host verifications of Airbnb listings in Hong Kong. 
  
##### 3.9.1. Transform by counting
```{r}
listings_nchar <- listings4 %>% 
  mutate(host_verifications = nchar(gsub('[^,]', '', host_verifications))+1,
         amenities = nchar(gsub('[^,]', '', amenities))+1)
```
  
* The number of host verifications
```{r}
ggplot(listings_nchar, aes(x = host_verifications)) + 
  geom_histogram(fill="black", colour="black", alpha = 0.25, binwidth=1)
```
```{r}
ggplot(data = listings_nchar, aes(x = host_verifications, y = cx_scores)) +
  geom_point() +
  geom_smooth(method = lm)
```
  
* The number of amenities
```{r}
ggplot(listings_nchar, aes(x = amenities)) + 
  geom_histogram(fill="black", colour="black", alpha = 0.25, binwidth=1)
```
```{r}
ggplot(data = listings_nchar, aes(x = amenities, y = cx_scores)) +
  geom_point() +
  geom_smooth(method = lm)
```
  
* Correlation
```{r}
corr_nchar <- as.data.frame(lapply(listings_nchar, function(x)cor(x, listings_nchar$cx_scores))) %>%
  gather(key = "var", value = "correlation") %>%
  arrange(desc(abs(correlation))) %>%
  filter(abs(correlation) > 0)
corr_nchar
```

##### 3.9.2. Transform using NLP
  
* Amenities
```{r}
amenities <- listings4 %>% unnest_tokens(word, amenities, token = "regex", pattern = "\\,|\\{|\\}")
frequency_amenities <-  amenities %>% count(word) %>% arrange(desc(n))
head(frequency_amenities,20)
```
  
* Host_verifications
```{r}
host_verifications <- listings4 %>% unnest_tokens(word, host_verifications, token = "regex", pattern = "\\,|\\[|\\]|\\'|\\s")
frequency_host_verifications <-  host_verifications %>% count(word) %>% arrange(desc(n))
head(frequency_host_verifications,10)
```
  
* Spread amenities and host verifications across multiple columns
```{r}
listings_nlp <- listings4 %>% 
  mutate(air_conditioning = case_when(tolower(amenities) %like% '%air conditioning%' ~ 1, TRUE ~ 0),
         wifi = case_when(tolower(amenities) %like% '%wifi%' ~ 1, TRUE ~ 0),
         essentials = case_when(tolower(amenities) %like% '%essentials%' ~ 1, TRUE ~ 0),
         shampoo = case_when(tolower(amenities) %like% '%shampoo%' ~ 1, TRUE ~ 0),
         tv = case_when(tolower(amenities) %like% "%tv,%" ~ 1, TRUE ~ 0),
         hangers = case_when(tolower(amenities) %like% "%hangers%" ~ 1, TRUE ~ 0),
         hair_dryer = case_when(tolower(amenities) %like% "%hair dryer%" ~ 1, TRUE ~ 0),
         elevator = case_when(tolower(amenities) %like% "%elevator%" ~ 1, TRUE ~ 0),
         kitchen = case_when(tolower(amenities) %like% "%kitchen%" ~ 1, TRUE ~ 0),
         hot_water = case_when(tolower(amenities) %like% "%hot water%" ~ 1, TRUE ~ 0),
         washer = case_when(tolower(amenities) %like% '%washer%' ~ 1, TRUE ~ 0),
         laptop_friendly_workspace = case_when(tolower(amenities) %like% '%laptop-friendly workspace%' ~ 1, TRUE ~ 0),
         family_kid_friendly = case_when(tolower(amenities) %like% '%family/kid friendly%' ~ 1, TRUE ~ 0),
         iron = case_when(tolower(amenities) %like% '%iron%' ~ 1, TRUE ~ 0),
         lock_on_bedroom_door = case_when(tolower(amenities) %like% "%lock on bedroom door%" ~ 1, TRUE ~ 0),
         smoke_alarm = case_when(tolower(amenities) %like% "%smoke alarm%" ~ 1, TRUE ~ 0),
         fire_extinguisher = case_when(tolower(amenities) %like% "%fire extinguisher%" ~ 1, TRUE ~ 0),
         refrigerator = case_when(tolower(amenities) %like% "%refrigerator%" ~ 1, TRUE ~ 0),
         heating = case_when(tolower(amenities) %like% "%heating%" ~ 1, TRUE ~ 0),
         long_term_stays_allowed = case_when(tolower(amenities) %like% "%long term stays allowed%" ~ 1, TRUE ~ 0),
         phone = case_when(tolower(host_verifications) %like% "%'phone'%" ~ 1, TRUE ~ 0),
         email = case_when(tolower(host_verifications) %like% "%'email'%" ~ 1, TRUE ~ 0),
         reviews = case_when(tolower(host_verifications) %like% "%'reviews'%" ~ 1, TRUE ~ 0),
         government_id = case_when(tolower(host_verifications) %like% "%'government_id'%" ~ 1, TRUE ~ 0),
         jumio = case_when(tolower(host_verifications) %like% "%'jumio'%" ~ 1, TRUE ~ 0),
         offline_government_id = case_when(tolower(host_verifications) %like% "%'offline_government_id'%" ~ 1, TRUE ~ 0),
         selfie = case_when(tolower(host_verifications) %like% "%'selfie'%" ~ 1, TRUE ~ 0),
         identity_manual = case_when(tolower(host_verifications) %like% "%'identity_manual'%" ~ 1, TRUE ~ 0),
         facebook = case_when(tolower(host_verifications) %like% "%'facebook'%" ~ 1, TRUE ~ 0),
         work_email = case_when(tolower(host_verifications) %like% "%'work_email'%" ~ 1, TRUE ~ 0)) %>% 
  dplyr::select(-amenities, -host_verifications)

names(listings_nlp) <- gsub(" ", "_", names(listings_nlp))
names(listings_nlp) <- gsub("&", "", names(listings_nlp))
```
  
* Correlation
```{r}
corr_nlp <- as.data.frame(lapply(listings_nlp, function(x)cor(x, listings_nlp$cx_scores))) %>%
  gather(key = "var", value = "correlation") %>%
  arrange(desc(abs(correlation))) %>%
  filter(abs(correlation) > 0)
corr_nlp
```

### 4. Summary Statistics
#### 4.1. Normalization
```{r}
numeric_var_nchar <- c("host_response_rate","host_acceptance_rate","accommodates","bathrooms","bedrooms","beds","price","weekly_price","monthly_price","security_deposit","cleaning_fee","guests_included","extra_people","minimum_nights","maximum_nights","minimum_minimum_nights","maximum_minimum_nights","minimum_maximum_nights","maximum_maximum_nights","minimum_nights_avg_ntm","maximum_nights_avg_ntm","calculated_host_listings_count","calculated_host_listings_count_entire_homes","calculated_host_listings_count_private_rooms","calculated_host_listings_count_shared_rooms","amenities","host_verifications","last_first_review")
for (var in numeric_var_nchar){
    text <- paste("listings_nchar$",var," <- normalize(listings_nchar$",var,",method='standardize')" ,sep='')
  eval(parse(text= text))
}
listings_nchar$cx_scores <- normalize(listings_nchar$cx_scores,method='center')
```
```{r}
numeric_var_nlp <- c("host_response_rate","host_acceptance_rate","accommodates","bathrooms","bedrooms","beds","price","weekly_price","monthly_price","security_deposit","cleaning_fee","guests_included","extra_people","minimum_nights","maximum_nights","minimum_minimum_nights","maximum_minimum_nights","minimum_maximum_nights","maximum_maximum_nights","minimum_nights_avg_ntm","maximum_nights_avg_ntm","calculated_host_listings_count","calculated_host_listings_count_entire_homes","calculated_host_listings_count_private_rooms","calculated_host_listings_count_shared_rooms","last_first_review")
for (var in numeric_var_nlp){
    text <- paste("listings_nlp$",var," <- normalize(listings_nlp$",var,",method='standardize')" ,sep='')
  eval(parse(text= text))
}
listings_nlp$cx_scores <- normalize(listings_nlp$cx_scores,method='center')
```
  
The next step is to drop insignificant variables from the regression models.

#### 4.2. Transform by counting
```{r}
# Remove insignificant variables
fit_nchar_ini <- lm(cx_scores~., listings_nchar)
sig_nchar <- summary(fit_nchar_ini)$coeff[-1,4] < 0.05
sig_nchar <- names(sig_nchar)[sig_nchar == TRUE] 
sig_formula_nchar <- as.formula(paste("cx_scores ~",paste(sig_nchar, collapse= "+")))
# Linear Regression Model
fit_nchar <- lm(sig_formula_nchar, listings_nchar)
summary(fit_nchar)
```
  
Further reduce dimensionality by removing insignificant variables
```{r,results = 'hide',message=FALSE}
# Summary Statistics
listings_reg_nchar <- listings_nchar[,append("cx_scores",sig_nchar)] %>% 
  dplyr::select(-minimum_minimum_nights,-Kowloon_City,-North,-Sha_Tin,-Southern,-Condominium,-Hotel_room)
stargazer(listings_reg_nchar,type='html',title = 'Summary Statistics',nobs = FALSE,out = 'summary_statistics_nchar.html')
```
```{r}
summary(listings_reg_nchar)
```

#### 4.3. Transform using nlp
```{r}
# Remove insignificant variables
fit_nlp_ini <- lm(cx_scores~., listings_nlp)
sig_nlp <- summary(fit_nlp_ini)$coeff[-1,4] < 0.05
sig_nlp <- names(sig_nlp)[sig_nlp == TRUE] 
sig_formula_nlp <- as.formula(paste("cx_scores ~",paste(sig_nlp, collapse= "+")))
# Linear Regression Model
fit_nlp <- lm(sig_formula_nlp, listings_nlp)
summary(fit_nlp)
```
  
Further reduce dimensionality by removing insignificant variables
```{r,results = 'hide',message=FALSE}
# Summary Statistics
listings_reg_nlp <- listings_nlp[,append("cx_scores",sig_nlp)] %>% 
  dplyr::select(-Central_Western,-North,-Sha_Tin,-Southern,-offline_government_id)
stargazer(listings_reg_nlp,type='html',title = 'Summary Statistics',nobs = FALSE,out = 'summary_statistics_nlp.html')
```
```{r}
summary(listings_reg_nlp)
```

### 5. Regression
#### 5.1. Linear Regression
##### 5.1.1. Transform by counting
```{r,results = 'hide',message=FALSE}
linear_model_nchar <- lm(cx_scores~., listings_reg_nchar)
stargazer(linear_model_nchar,type='html',title = 'Linear Regression Model', out = 'linear_regression_model_nchar.html')
```
  
* RMSE
```{r}
sqrt(mean(linear_model_nchar$residuals^2))
```
  
##### 5.1.2. Transform using NLP
```{r,results = 'hide',message=FALSE}
linear_model_nlp <- lm(cx_scores~., listings_reg_nlp)
stargazer(linear_model_nlp,type='html',title = 'Linear Regression Model', out = 'linear_regression_model_nlp.html')
```
  
* RMSE
```{r}
sqrt(mean(linear_model_nlp$residuals^2))
```

##### 5.1.3. Training dataset and testing dataset
  
We now split the samples into a training set and a testing set in order to estimate the test error of linear regression, ridge regression, and the lasso.
```{r}
train = listings_reg_nlp %>% sample_frac(0.8)
test = listings_reg_nlp %>% setdiff(train)

x_train = model.matrix(cx_scores~., train)[,-1]
x_test = model.matrix(cx_scores~., test)[,-1]

y_train = train %>%
  dplyr::select(cx_scores) %>%
  unlist() %>%
  as.numeric()
y_test = test %>%
  dplyr::select(cx_scores) %>%
  unlist() %>%
  as.numeric()
```
  
* RMSE
```{r}
linear_train <- lm(cx_scores~., train)
linear_pred <- predict(linear_train, newx = x_test)
sqrt(mean((linear_pred - y_test)^2))
```

#### 5.2. Ridge Regression
```{r}
# outcome
y <- listings_reg_nlp$cx_scores

# Predictors as matrix 
x <- listings_reg_nlp %>% dplyr::select(-cx_scores) %>% data.matrix()

# Set up the hyperparameter, lambda - this is the strength of the penalty for each residual 
lambdas <- 10^seq(3, -2, by = -.1)

# Find optimal lambda using cross-validation - running the model many times for different values of lambda
cv_ridge_model <- cv.glmnet(x, y, alpha = 0, lambda = lambdas)
plot(cv_ridge_model)
```
  
So we now have the optimal lambda for our value. We can extract this value to work with it:
```{r}
opt_lambda <- cv_ridge_model$lambda.min
opt_lambda
```
  
Now we have our trained models as below:
```{r}
ridge_model <- cv_ridge_model$glmnet.fit
summary(ridge_model)
```
  
We can also visualize the coefficients as below, where each curve is a variable
```{r}
plot(ridge_model, label = TRUE)
```
  
And we can see how good the training model is: 
```{r}
ridge_y_pred <- predict(ridge_model, s = opt_lambda, newx = x)

# Sum of Squares Total and Error
sst <- sum((y - mean(y))^2)
sse <- sum((ridge_y_pred - y)^2)

# R squared
rsq <- 1 - sse / sst
rsq
```
  
RMSE
```{r}
ridge_train <- glmnet(x_train, y_train, alpha=0, lambda = lambdas)
ridge_pred <- predict(ridge_train, s = opt_lambda, newx = x_test)
sqrt(mean((ridge_pred - y_test)^2))
```

#### 5.3. Lasso Regression
```{r}
lasso_model <- glmnet(x, y, alpha = 1, lambda = lambdas)
plot(lasso_model, label = TRUE)    # Draw plot of coefficients
```
  
Notice that in the coefficient plot that depending on the choice of tuning parameter, some of the coefficients are exactly equal to zero. We now perform cross-validation and compute the associated test error:
```{r}
cv_lasso_model <- cv.glmnet(x, y, alpha = 1) # Fit lasso model on training data
plot(cv_lasso_model) # Draw plot of training MSE as a function of lambda
```
  
The optimal lambda is: 
```{r}
opt_lambda <- cv_lasso_model$lambda.min
lasso_y_pred <- predict(lasso_model, s = opt_lambda, newx = x)
opt_lambda
```
And we can see how good the training model is: 
```{r}
# Sum of Squares Total and Error
sst <- sum((y - mean(y))^2)
sse <- sum((lasso_y_pred - y)^2)

# R squared
rsq <- 1 - sse / sst
rsq
```
  
RMSE
```{r}
lasso_train <- glmnet(x_train, y_train, alpha=1, lambda = lambdas)
lasso_pred <- predict(lasso_model, s = opt_lambda, newx = x_test) # Use best lambda to predict test data
sqrt(mean((lasso_pred - y_test)^2))
```

#### 5.4. Random Forest
```{r}
oob.err=double(13)
test.err=double(13)
#mtry is the number of variables randomly chosen at each split
for(mtry in 1:13) 
{
  rf=randomForest(cx_scores ~ . , data = train,mtry=mtry,ntree=400) 
  oob.err[mtry] = rf$mse[400] #Error of all Trees fitted
  
  pred<-predict(rf,test) #Predictions on Test Set for each Tree
  test.err[mtry]= with(test, mean((cx_scores - pred)^2)) #Mean Squared Test Error
  
  cat(mtry," ") #printing the output to the console
}
```
```{r}
matplot(1:mtry, cbind(oob.err,test.err), pch=19, col=c("red","blue"), type="b", ylab="Mean Squared Error", xlab="Number of Predictors Considered at each Split")
legend("topright", legend=c("Out of Bag Error","Test Error"), pch=19, col=c("red","blue"))
```
  
Test error is the smallest when mtry = 7. Let ntree = 300
```{r}
rf_model <- randomForest(cx_scores ~ . , data = train, mtry = 7, ntree=300)
rf_model
```
```{r}
plot(rf_model)
```
  
RMSE
```{r}
rf_pred <- predict(rf_model,test)
sqrt(mean((rf_pred - y_test)^2))
```